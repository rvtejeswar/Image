{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "from tkinter import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define `net` as a global variable (if necessary)\n",
    "global net\n",
    "\n",
    "# Load YOLO model and COCO class labels\n",
    "model_path = \"yolov3.weights\"\n",
    "config_path = \"yolov3.cfg\"\n",
    "\n",
    "# Load the YOLO model with GPU acceleration\n",
    "net = cv2.dnn.readNet(model_path, config_path)\n",
    "\n",
    "def Label_objects(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    unconnected_out_layers = net.getUnconnectedOutLayers()\n",
    "    if isinstance(unconnected_out_layers, int):\n",
    "        return [layer_names[unconnected_out_layers - 1]]  # Return a list with a single layer\n",
    "    else:\n",
    "        return [layer_names[i - 1] for i in unconnected_out_layers]  # Multiple layers\n",
    "\n",
    "def detect_objects(filename, output_window):\n",
    "    \"\"\"Detects objects in a video using the loaded YOLO model.\"\"\"\n",
    "\n",
    "    # Check if the YOLO model has been loaded\n",
    "    if net is None:\n",
    "        print(\"Please select a video file first.\")\n",
    "        return\n",
    "\n",
    "    # Load the COCO class names\n",
    "    classes = []\n",
    "    with open(\"coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    target_width, target_height = 600, 440  # Set the target size for resizing\n",
    "\n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize the frame to the target size\n",
    "        image = cv2.resize(image, (target_width, target_height))\n",
    "\n",
    "        # Create a blob from the resized image\n",
    "        blob = cv2.dnn.blobFromImage(image, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "        # Set the blob as the input to the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Perform a forward pass to obtain the output layer values\n",
    "        outs = net.forward(Label_objects(net))\n",
    "\n",
    "        # Process the outputs and perform non-maximum suppression\n",
    "        post_process(image, outs, classes)\n",
    "\n",
    "        # Display the resized image with the bounding boxes and labels\n",
    "        cv2.imshow(output_window, image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def post_process(image, outs, classes):\n",
    "    frame_height, frame_width = image.shape[:2]\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * frame_width)\n",
    "                center_y = int(detection[1] * frame_height)\n",
    "                w = int(detection[2] * frame_width)\n",
    "                h = int(detection[3] * frame_height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    if len(indices) > 0:  # Check if indices is not empty\n",
    "        for i in indices.flatten():\n",
    "            box = boxes[i]\n",
    "            x, y, w, h = box[0], box[1], box[2], box[3]\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(image, classes[class_ids[i]], (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "def browse_video():\n",
    "    \"\"\"Loads the YOLO model, prompts for a video file, and launches object detection.\"\"\"\n",
    "    \n",
    "    if net is None:\n",
    "        print(\"Error: Could not load the model. Please check the file paths.\")\n",
    "        return\n",
    "\n",
    "    # Open a dialog to select a video file\n",
    "    filename = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "    if filename:\n",
    "        detect_objects(filename, \"Object Detection\")\n",
    "\n",
    "def start_webcam_streaming():\n",
    "    \"\"\"Starts webcam object detection.\"\"\"\n",
    "\n",
    "    if net is None:\n",
    "        print(\"Error: Could not load the model. Please check the file paths.\")\n",
    "        return\n",
    "\n",
    "    detect_objects(0, \"Webcam Object Detection\")\n",
    "\n",
    "# Create Tkinter GUI\n",
    "\n",
    "from PIL import Image,ImageTk\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Object Detection\")\n",
    "\n",
    "frame = tk.Frame(root, width=1920, height=1080)\n",
    "\n",
    "msg=Message(frame,text=\"Object Tracking using Deep Learning\")\n",
    "\n",
    "# Add a background image to the frame\n",
    "bg_image = Image.open(\"Image.png\")\n",
    "bg_image = bg_image.resize((1580, 850), Image.Resampling.LANCZOS)\n",
    "bg_image = ImageTk.PhotoImage(bg_image)\n",
    "background_label = tk.Label(frame, image=bg_image)\n",
    "background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "\n",
    "\n",
    "browse_button = ttk.Button(root, text=\"Browse System Video\", command=browse_video).place(x=700, y=400)\n",
    "webcam_button = ttk.Button(root, text=\"Start Webcam Streaming\", command=start_webcam_streaming).place(x=690, y=450)\n",
    "\n",
    "frame.propagate(0)\n",
    "\n",
    "frame.pack()\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba776c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
